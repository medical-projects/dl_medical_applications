{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast_cancer_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPixQELhOlnPxQLGlr3iuVW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi7299/dl_medical_applications/blob/master/Breast_cancer_classification_cancernet/Breast_cancer_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_eTalFTdsOf",
        "colab_type": "code",
        "outputId": "923c5f0b-44e5-4e35-9e59-679ba13e3a1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "\n",
        "\n",
        "## load kaggle api token for downloading data from kaggle\n",
        "!wget --no-check-certificate \\\n",
        "     https://kaggleapitoken.s3.amazonaws.com/kaggle.json \n",
        "    \n",
        "\n",
        "\n",
        "#from google.colab import files\n",
        "#files.upload() #upload kaggle.json\n",
        "\n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "#!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-21 10:19:36--  https://kaggleapitoken.s3.amazonaws.com/kaggle.json\n",
            "Resolving kaggleapitoken.s3.amazonaws.com (kaggleapitoken.s3.amazonaws.com)... 52.216.106.75\n",
            "Connecting to kaggleapitoken.s3.amazonaws.com (kaggleapitoken.s3.amazonaws.com)|52.216.106.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 63 [application/json]\n",
            "Saving to: ‘kaggle.json’\n",
            "\n",
            "\rkaggle.json           0%[                    ]       0  --.-KB/s               \rkaggle.json         100%[===================>]      63  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-21 10:19:36 (1.48 MB/s) - ‘kaggle.json’ saved [63/63]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSBjkgvR8ta_",
        "colab_type": "code",
        "outputId": "6f229b3f-2fac-4774-ed85-8dd37951f090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcdciAajCv3f",
        "colab_type": "code",
        "outputId": "e2c9f468-6cfb-4608-c8be-eeb44555a41f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "##download paultimothymooney/breast-histopathology-images dataset zip in /content\n",
        "!kaggle datasets download -d paultimothymooney/breast-histopathology-images -p /content --force"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading breast-histopathology-images.zip to /content\n",
            "100% 3.09G/3.10G [00:53<00:00, 36.0MB/s]\n",
            "100% 3.10G/3.10G [00:53<00:00, 62.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrYVjZ1rDFy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unzip dataset\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = 'breast-histopathology-images.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/data/')\n",
        "zip_ref.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcyyeQhUHeDT",
        "colab_type": "code",
        "outputId": "28b0df55-acb6-4951-8481-c5a592944897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "#to view file structure\n",
        "!apt-get install tree"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 40.7 kB of archives.\n",
            "After this operation, 105 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n",
            "Fetched 40.7 kB in 0s (660 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 144433 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsuUHaqi89dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!tree --dirsfirst -L 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4HyjrJ_Hq02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        "\n",
        "ORIG_INPUT_DATASET = \"./data\"\n",
        "\n",
        "#!mkdir -p ./final_data\n",
        "BASE_PATH = \"./final_data\"\n",
        "\n",
        "#!mkdir -p ./final_data/training\n",
        "#!mkdir -p ./final_data/validation\n",
        "#!mkdir -p ./final_data/testing\n",
        "\n",
        "TRAIN_PATH = os.path.sep.join([BASE_PATH, \"training\"])\n",
        "VAL_PATH = os.path.sep.join([BASE_PATH, \"validation\"])\n",
        "TEST_PATH = os.path.sep.join([BASE_PATH, \"testing\"])\n",
        "\n",
        "TRAIN_SPLIT = 0.8\n",
        "\n",
        "\n",
        "VAL_SPLIT = 0.1  # remaining 0.1 data foor testing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFy-ek9nKst8",
        "colab_type": "code",
        "outputId": "0572c906-6f11-4701-d32a-479896a25e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from imutils import paths\n",
        "import random\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# list and shuffle image paths\n",
        "imagePaths = list(paths.list_images(ORIG_INPUT_DATASET))\n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)\n",
        "\n",
        "print(len(imagePaths))\n",
        "\n",
        "# compute the training and testing split\n",
        "i = int(len(imagePaths) * TRAIN_SPLIT)\n",
        "trainPaths = imagePaths[:i]\n",
        "testPaths = imagePaths[i:]\n",
        "\n",
        "# validation and test split\n",
        "i = int(len(trainPaths) * VAL_SPLIT)\n",
        "valPaths = trainPaths[:i]\n",
        "trainPaths = trainPaths[i:]\n",
        "\n",
        "# datasets building\n",
        "datasets = [\n",
        "\t(\"training\", trainPaths, TRAIN_PATH),\n",
        "\t(\"validation\", valPaths, VAL_PATH),\n",
        "\t(\"testing\", testPaths, TEST_PATH)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "555048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MZEnmu_M-OU",
        "colab_type": "code",
        "outputId": "b50dba59-a4c9-4ea9-9590-58bf8477a70a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "for (dType, imagePaths, baseOutput) in datasets:\n",
        "\n",
        "\tprint(\"[INFO] building '{}' split\".format(dType))\n",
        "\n",
        "\tif not os.path.exists(baseOutput):\n",
        "\t\tprint(\"[INFO] 'creating {}' directory\".format(baseOutput))\n",
        "\t\tos.makedirs(baseOutput)\n",
        "\n",
        "\tfor inputPath in imagePaths:\n",
        "\t\tfilename = inputPath.split(os.path.sep)[-1]\n",
        "\t\tlabel = filename[-5:-4]\n",
        "\t\t\n",
        "\t\tlabelPath = os.path.sep.join([baseOutput, label])\n",
        "\t\n",
        "\t\tif not os.path.exists(labelPath):\n",
        "\t\t\tprint(\"[INFO] 'creating {}' directory\".format(labelPath))\n",
        "\t\t\tos.makedirs(labelPath)\n",
        "\t\t\n",
        "\t\tp = os.path.sep.join([labelPath, filename])\n",
        "\t\tshutil.copy2(inputPath, p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] building 'training' split\n",
            "[INFO] 'creating ./final_data/training' directory\n",
            "[INFO] 'creating ./final_data/training/0' directory\n",
            "[INFO] 'creating ./final_data/training/1' directory\n",
            "[INFO] building 'validation' split\n",
            "[INFO] 'creating ./final_data/validation' directory\n",
            "[INFO] 'creating ./final_data/validation/0' directory\n",
            "[INFO] 'creating ./final_data/validation/1' directory\n",
            "[INFO] building 'testing' split\n",
            "[INFO] 'creating ./final_data/testing' directory\n",
            "[INFO] 'creating ./final_data/testing/0' directory\n",
            "[INFO] 'creating ./final_data/testing/1' directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bfpm7pGLc7l",
        "colab_type": "code",
        "outputId": "1ec72b33-e03a-4349-9a7e-5a7e2ee8c991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "!tree  -p \"./final_data\" --dirsfirst --filelimit 10 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./final_data\n",
            "├── [drwxr-xr-x]  testing\n",
            "│   ├── [drwxr-xr-x]  0 [71691 entries exceeds filelimit, not opening dir]\n",
            "│   └── [drwxr-xr-x]  1 [28256 entries exceeds filelimit, not opening dir]\n",
            "├── [drwxr-xr-x]  training\n",
            "│   ├── [drwxr-xr-x]  0 [183177 entries exceeds filelimit, not opening dir]\n",
            "│   └── [drwxr-xr-x]  1 [72628 entries exceeds filelimit, not opening dir]\n",
            "└── [drwxr-xr-x]  validation\n",
            "    ├── [drwxr-xr-x]  0 [30450 entries exceeds filelimit, not opening dir]\n",
            "    └── [drwxr-xr-x]  1 [12160 entries exceeds filelimit, not opening dir]\n",
            "\n",
            "9 directories, 0 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opyVNns-O6Vt",
        "colab_type": "code",
        "outputId": "dded754f-c3f8-4d43-ad72-ca0143d110dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import SeparableConv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K\n",
        "\n",
        "class CancerNet:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes):\n",
        "\t\t\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "\n",
        "\t\t\n",
        "\t\tif K.image_data_format() == \"channels_first\":\n",
        "\t\t\tinputShape = (depth, height, width)\n",
        "\t\t\tchanDim = 1\n",
        "\n",
        "\t\t# CONV => RELU => POOL\n",
        "\t\tmodel.add(SeparableConv2D(32, (3, 3), padding=\"same\",\n",
        "\t\t\tinput_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t\t# (CONV => RELU => POOL) * 2\n",
        "\t\tmodel.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(SeparableConv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t\t# (CONV => RELU => POOL) * 3\n",
        "\t\tmodel.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(SeparableConv2D(128, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t\t# first (and only) set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(256))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\t\tmodel.add(Dropout(0.5))\n",
        "\n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(\"softmax\"))\n",
        "\n",
        "\t\treturn model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1g_HmjFUjoa",
        "colab_type": "code",
        "outputId": "cfa9458a-a37b-47fa-80bc-cd3d535fa33f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.optimizers import Adagrad\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "INIT_LR = 1e-2\n",
        "BS = 32\n",
        "\n",
        "\n",
        "trainPaths = list(paths.list_images(TRAIN_PATH))\n",
        "totalTrain = len(trainPaths)\n",
        "totalVal = len(list(paths.list_images(VAL_PATH)))\n",
        "totalTest = len(list(paths.list_images(TEST_PATH)))\n",
        "\n",
        "trainLabels = [int(p.split(os.path.sep)[-2]) for p in trainPaths]\n",
        "trainLabels = np_utils.to_categorical(trainLabels)\n",
        "classTotals = trainLabels.sum(axis=0)\n",
        "classWeight = classTotals.max() / classTotals\n",
        "\n",
        "trainAug = ImageDataGenerator(\n",
        "\trescale=1 / 255.0,\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.05,\n",
        "\twidth_shift_range=0.1,\n",
        "\theight_shift_range=0.1,\n",
        "\tshear_range=0.05,\n",
        "\thorizontal_flip=True,\n",
        "\tvertical_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "\n",
        "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
        "\n",
        "trainGen = trainAug.flow_from_directory(\n",
        "\tTRAIN_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(48, 48),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=True,\n",
        "\tbatch_size=BS)\n",
        "\n",
        "valGen = valAug.flow_from_directory(\n",
        "\tVAL_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(48, 48),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BS)\n",
        "\n",
        "testGen = valAug.flow_from_directory(\n",
        "\tTEST_PATH,\n",
        "\tclass_mode=\"categorical\",\n",
        "\ttarget_size=(48, 48),\n",
        "\tcolor_mode=\"rgb\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=BS)\n",
        "\n",
        "model = CancerNet.build(width=48, height=48, depth=3,\n",
        "\tclasses=2)\n",
        "opt = Adagrad(lr=INIT_LR, decay=INIT_LR / NUM_EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# fit the model\n",
        "H = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=totalTrain // BS,\n",
        "\tvalidation_data=valGen,\n",
        "\tvalidation_steps=totalVal // BS,\n",
        "\tclass_weight=classWeight,\n",
        "\tepochs=NUM_EPOCHS)\n",
        "\n",
        "# reset the testing generator and then use our trained model to\n",
        "# make predictions on the data\n",
        "print(\"[INFO] evaluating network...\")\n",
        "testGen.reset()\n",
        "predIdxs = model.predict_generator(testGen,\n",
        "\tsteps=(totalTest // BS) + 1)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testGen.classes, predIdxs,\n",
        "\ttarget_names=testGen.class_indices.keys()))\n",
        "\n",
        "# compute the confusion matrix and and use it to derive the raw\n",
        "# accuracy, sensitivity, and specificity\n",
        "cm = confusion_matrix(testGen.classes, predIdxs)\n",
        "total = sum(sum(cm))\n",
        "acc = (cm[0, 0] + cm[1, 1]) / total\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "\n",
        "# show the confusion matrix, accuracy, sensitivity, and specificity\n",
        "print(cm)\n",
        "print(\"acc: {:.4f}\".format(acc))\n",
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 255805 images belonging to 2 classes.\n",
            "Found 42610 images belonging to 2 classes.\n",
            "Found 99947 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "7993/7993 [==============================] - 687s 86ms/step - loss: 0.3928 - accuracy: 0.8372 - val_loss: 0.2046 - val_accuracy: 0.8488\n",
            "Epoch 2/10\n",
            "7993/7993 [==============================] - 472s 59ms/step - loss: 0.3636 - accuracy: 0.8465 - val_loss: 0.2611 - val_accuracy: 0.8461\n",
            "Epoch 3/10\n",
            "7993/7993 [==============================] - 462s 58ms/step - loss: 0.3603 - accuracy: 0.8480 - val_loss: 0.9710 - val_accuracy: 0.8451\n",
            "Epoch 4/10\n",
            "7993/7993 [==============================] - 473s 59ms/step - loss: 0.3583 - accuracy: 0.8490 - val_loss: 0.8860 - val_accuracy: 0.8507\n",
            "Epoch 5/10\n",
            "7993/7993 [==============================] - 470s 59ms/step - loss: 0.3573 - accuracy: 0.8489 - val_loss: 0.1508 - val_accuracy: 0.8498\n",
            "Epoch 6/10\n",
            "7993/7993 [==============================] - 471s 59ms/step - loss: 0.3560 - accuracy: 0.8493 - val_loss: 0.3393 - val_accuracy: 0.8506\n",
            "Epoch 7/10\n",
            "7993/7993 [==============================] - 466s 58ms/step - loss: 0.3551 - accuracy: 0.8507 - val_loss: 0.3188 - val_accuracy: 0.8500\n",
            "Epoch 8/10\n",
            "7993/7993 [==============================] - 458s 57ms/step - loss: 0.3555 - accuracy: 0.8495 - val_loss: 0.2297 - val_accuracy: 0.8512\n",
            "Epoch 9/10\n",
            "7993/7993 [==============================] - 454s 57ms/step - loss: 0.3549 - accuracy: 0.8500 - val_loss: 0.2783 - val_accuracy: 0.8503\n",
            "Epoch 10/10\n",
            "7993/7993 [==============================] - 462s 58ms/step - loss: 0.3546 - accuracy: 0.8495 - val_loss: 0.3318 - val_accuracy: 0.8502\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.88      0.89     71691\n",
            "           1       0.72      0.77      0.74     28256\n",
            "\n",
            "    accuracy                           0.85     99947\n",
            "   macro avg       0.81      0.82      0.82     99947\n",
            "weighted avg       0.85      0.85      0.85     99947\n",
            "\n",
            "[[63094  8597]\n",
            " [ 6621 21635]]\n",
            "acc: 0.8477\n",
            "sensitivity: 0.8801\n",
            "specificity: 0.7657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7ec67544bc5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Loss and Accuracy on Dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKW3TnZtIoJU",
        "colab_type": "code",
        "outputId": "96968603-79af-4476-81ef-60ca9dee4699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# plot the training loss and accuracy\n",
        "N = NUM_EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "\n",
        "print(H.history.keys())\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"plot.png\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N07Ch0UxWHrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Breast_cancer_classification_cancernet.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BPgtW-WX89H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"Breast_cancer_classification_cancernet.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0vhiwidbWux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download(\"plot.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvVmLE549wDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}